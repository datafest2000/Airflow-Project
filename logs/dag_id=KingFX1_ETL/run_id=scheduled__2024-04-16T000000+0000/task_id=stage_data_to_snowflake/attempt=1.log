[2024-04-17T15:37:52.020+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: KingFX1_ETL.stage_data_to_snowflake scheduled__2024-04-16T00:00:00+00:00 [queued]>
[2024-04-17T15:37:52.030+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: KingFX1_ETL.stage_data_to_snowflake scheduled__2024-04-16T00:00:00+00:00 [queued]>
[2024-04-17T15:37:52.030+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-04-17T15:37:52.043+0000] {taskinstance.py:2217} INFO - Executing <Task(SnowflakeOperator): stage_data_to_snowflake> on 2024-04-16 00:00:00+00:00
[2024-04-17T15:37:52.048+0000] {standard_task_runner.py:60} INFO - Started process 63 to run task
[2024-04-17T15:37:52.051+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'KingFX1_ETL', 'stage_data_to_snowflake', 'scheduled__2024-04-16T00:00:00+00:00', '--job-id', '171', '--raw', '--subdir', 'DAGS_FOLDER/include/fx_dag.py', '--cfg-path', '/tmp/tmpxxbhkrn7']
[2024-04-17T15:37:52.054+0000] {standard_task_runner.py:88} INFO - Job 171: Subtask stage_data_to_snowflake
[2024-04-17T15:37:52.101+0000] {task_command.py:423} INFO - Running <TaskInstance: KingFX1_ETL.stage_data_to_snowflake scheduled__2024-04-16T00:00:00+00:00 [running]> on host 65f2ce3f86e2
[2024-04-17T15:37:52.173+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='KingFX1_ETL' AIRFLOW_CTX_TASK_ID='stage_data_to_snowflake' AIRFLOW_CTX_EXECUTION_DATE='2024-04-16T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-04-16T00:00:00+00:00'
[2024-04-17T15:37:52.175+0000] {sql.py:276} INFO - Executing:  
    PUT file://./opt/***/raw/data.csv @~
     
[2024-04-17T15:37:52.187+0000] {base.py:83} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-04-17T15:37:52.196+0000] {base.py:83} INFO - Using connection ID 'snowflake_conn' for task execution.
[2024-04-17T15:37:52.197+0000] {connection.py:386} INFO - Snowflake Connector for Python Version: 3.7.1, Python Version: 3.8.19, Platform: Linux-5.15.146.1-microsoft-standard-WSL2-x86_64-with-glibc2.34
[2024-04-17T15:37:52.198+0000] {connection.py:1211} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-04-17T15:37:59.386+0000] {cursor.py:1032} INFO - query: [ALTER SESSION SET autocommit=True]
[2024-04-17T15:37:59.714+0000] {cursor.py:1045} INFO - query execution done
[2024-04-17T15:37:59.715+0000] {cursor.py:1205} INFO - Number of results in first chunk: 1
[2024-04-17T15:37:59.715+0000] {sql.py:457} INFO - Running statement: PUT file://./opt/***/raw/data.csv @~, parameters: None
[2024-04-17T15:37:59.716+0000] {cursor.py:1032} INFO - query: [PUT file://./opt/***/raw/data.csv @~]
[2024-04-17T15:37:59.998+0000] {cursor.py:1045} INFO - query execution done
[2024-04-17T15:38:06.442+0000] {sql.py:466} INFO - Rows affected: 1
[2024-04-17T15:38:06.443+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/providers/snowflake/hooks/snowflake.py:393: AirflowProviderDeprecationWarning: Call to deprecated method _make_common_data_structure. (The `_make_serializable` method is deprecated and support will be removed in a future version of the common.sql provider. Please update the DbApiHook's provider to a version based on common.sql >= 1.9.1.)
  result = self._make_common_data_structure(handler(cur))  # type: ignore[attr-defined]

[2024-04-17T15:38:06.444+0000] {snowflake.py:402} INFO - Rows affected: 1
[2024-04-17T15:38:06.444+0000] {snowflake.py:403} INFO - Snowflake query id: 01b3bb69-0000-dd27-0000-0001958e9005
[2024-04-17T15:38:06.446+0000] {connection.py:734} INFO - closed
[2024-04-17T15:38:06.605+0000] {connection.py:740} INFO - No async queries seem to be running, deleting session
[2024-04-17T15:38:06.818+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=KingFX1_ETL, task_id=stage_data_to_snowflake, execution_date=20240416T000000, start_date=20240417T153752, end_date=20240417T153806
[2024-04-17T15:38:06.849+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-04-17T15:38:06.871+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/models/baseoperator.py:1201: AirflowProviderDeprecationWarning: Call to deprecated class SnowflakeOperator. (This class is deprecated. Please use `***.providers.common.sql.operators.sql.SQLExecuteQueryOperator`. Also, you can provide `hook_params={'warehouse': <warehouse>, 'database': <database>, 'role': <role>, 'schema': <schema>, 'authenticator': <authenticator>,'session_parameters': <session_parameters>}`.)
  result = cls.__new__(cls)

[2024-04-17T15:38:06.908+0000] {taskinstance.py:3312} INFO - 1 downstream tasks scheduled from follow-on schedule check
